{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adf861db-b35a-4454-ae20-9c244e634631",
   "metadata": {},
   "source": [
    "# Modular coding - Lightning & MLflow\n",
    "\n",
    "MLflow has good support for PyTorch Lightning. Let's explore that a bit.\n",
    "\n",
    "First we need the usual imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d201bb5-3f26-4408-b75f-75088f55f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed modules\n",
    "import torch\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightning as L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a17b8e-a330-4b3f-8795-18074ecd15bd",
   "metadata": {},
   "source": [
    "## Data handling - LightningDataModule\n",
    "\n",
    "We again will define the LightningDataModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1b3d53-ae89-4ff2-b27f-24747e95edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "\n",
    "    def __init__(self, data_dir=\"../data\", batch_size=32):\n",
    "        # In init-function you can set arguments like data paths\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # setup-function is used to specify the datasets\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = datasets.MNIST(\n",
    "                self.data_dir, train=True, download=True, transform=ToTensor()\n",
    "            )\n",
    "        if stage == \"test\":\n",
    "            self.test_dataset = datasets.MNIST(\n",
    "                self.data_dir, train=False, transform=ToTensor()\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # train_dataloader specifies how to set up a training dataloader\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # test_dataloader specifies how to set up a test dataloader\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc067d4-8dd6-4b50-896e-e910ee14bcfa",
   "metadata": {},
   "source": [
    "## Model writing - LightningModule\n",
    "\n",
    "Let's again define the LightningModule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47c24e24-8500-4022-a8fe-8bf9abee3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(L.LightningModule):\n",
    "    def __init__(self, hidden_size=20):\n",
    "        # Init is done similar to nn.Module\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, 10),\n",
    "        )\n",
    "        # We specify loss function in the module as well\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward is done similar to nn.Module\n",
    "        return self.layers(x)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        # training_step-function specifies how data is fed into the model and how the loss is calculated\n",
    "        data, target = batch\n",
    "        outputs = self(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.loss(outputs, target)\n",
    "\n",
    "        # Count number of correct digits\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == target).sum().item()\n",
    "\n",
    "        batch_size = outputs.shape[0]\n",
    "\n",
    "        # Log loss and number of correct predictions\n",
    "        self.log(\"training_loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.log(\n",
    "            \"training_accuracy\", correct / batch_size, on_epoch=True, on_step=False\n",
    "        )\n",
    "\n",
    "        # training_step returns the loss\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch):\n",
    "        # test_step-function specifies how data is fed into the model and how the loss is calculated\n",
    "        data, target = batch\n",
    "        outputs = self(data)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = self.loss(outputs, target)\n",
    "\n",
    "        # Count number of correct digits\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == target).sum().item()\n",
    "\n",
    "        batch_size = outputs.shape[0]\n",
    "\n",
    "        # Log loss and number of correct predictions\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False)\n",
    "        self.log(\"test_accuracy\", correct / batch_size, on_epoch=True, on_step=False)\n",
    "\n",
    "        # training_step returns the loss\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # configure_optimizers-function specifies how the optimizer is created\n",
    "        return torch.optim.AdamW(self.layers.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77474e9-a845-45c8-ae29-b11bcf1bf702",
   "metadata": {},
   "source": [
    "## Logging - MLflow autologger\n",
    "\n",
    "This time let's use MLflow's [autologging feature](https://mlflow.org/docs/latest/ml/tracking/autolog#autolog-pytorch) that supports automatic logging from PyTorch Lightning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94e17d3f-fc84-490f-800c-f3199efb4c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"file:///tmp/mlflow/db\")\n",
    "\n",
    "experiment_name = \"mnist-lightning\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mlflow.pytorch.autolog(checkpoint_save_best_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dfb890-0177-4391-9e60-a39df21f70ae",
   "metadata": {},
   "source": [
    "## Training - Trainer\n",
    "\n",
    "We specify Trainer like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b993794-915d-4a77-8748-4bc79d9c2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1178d62-da28-4a91-a103-d34af8922f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/work/tuomiss1/conda_envs/ml-reproducibility/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/work/tuomiss1/conda_envs/ml-reproducibility ...\n",
      "INFO:pytorch_lightning.utilities.rank_zero:ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: False, used: False\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "model = SimpleMLP()\n",
    "datamodule = MNISTDataModule()\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=5,\n",
    "    callbacks=[TQDMProgressBar(refresh_rate=100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6f277-a023-4f61-8883-7adcf913d02a",
   "metadata": {},
   "source": [
    "This time we however wrap the `trainer.fit`-call under `mlflow.start_run`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01053388-4ac8-42c2-8ca3-c188cb183dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/work/tuomiss1/conda_envs/ml-reproducibility/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /scratch/work/tuomiss1/conda_envs/ml-reproducibility ...\n",
      "\n",
      "  | Name   | Type             | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | layers | Sequential       | 15.9 K | train\n",
      "1 | loss   | CrossEntropyLoss | 0      | train\n",
      "----------------------------------------------------\n",
      "15.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.9 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:11<00:00, 160.95it/s, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1875/1875 [00:11<00:00, 160.37it/s, v_num=4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/11 00:04:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309eedf-cf77-4870-9787-1311930a760d",
   "metadata": {},
   "source": [
    "## Examining the output\n",
    "\n",
    "We can see that MLflow automatically recorded plenty of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "861742b2-3520-4ca8-9f2b-2a1dd763d2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.training_accuracy</th>\n",
       "      <th>metrics.training_loss</th>\n",
       "      <th>params.differentiable</th>\n",
       "      <th>params.capturable</th>\n",
       "      <th>...</th>\n",
       "      <th>params.maximize</th>\n",
       "      <th>params.fused</th>\n",
       "      <th>params.weight_decay</th>\n",
       "      <th>tags.mlflow.latest_checkpoint_artifact</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.Mode</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.autologging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>813832b599c34bf38414eaa025b6845d</td>\n",
       "      <td>747633508105639431</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///tmp/mlflow/db/747633508105639431/81383...</td>\n",
       "      <td>2025-11-10 22:03:42.797000+00:00</td>\n",
       "      <td>2025-11-10 22:04:49.251000+00:00</td>\n",
       "      <td>0.950533</td>\n",
       "      <td>0.168893</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>checkpoints/epoch_4/checkpoint.pth</td>\n",
       "      <td>tuomiss1</td>\n",
       "      <td>/scratch/work/tuomiss1/conda_envs/ml-reproduci...</td>\n",
       "      <td>training</td>\n",
       "      <td>dashing-hen-904</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a76fc81ba9f441c09c58c0e2d3b4a056</td>\n",
       "      <td>747633508105639431</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///tmp/mlflow/db/747633508105639431/a76fc...</td>\n",
       "      <td>2025-11-10 21:58:47.133000+00:00</td>\n",
       "      <td>2025-11-10 21:59:50.084000+00:00</td>\n",
       "      <td>0.952867</td>\n",
       "      <td>0.164744</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>checkpoints/epoch_4/checkpoint.pth</td>\n",
       "      <td>tuomiss1</td>\n",
       "      <td>/scratch/work/tuomiss1/conda_envs/ml-reproduci...</td>\n",
       "      <td>training</td>\n",
       "      <td>fortunate-loon-636</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cb6348373b004ecc98032a51a769b8a2</td>\n",
       "      <td>747633508105639431</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>file:///tmp/mlflow/db/747633508105639431/cb634...</td>\n",
       "      <td>2025-11-10 21:58:07.339000+00:00</td>\n",
       "      <td>2025-11-10 21:58:07.346000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tuomiss1</td>\n",
       "      <td>/scratch/work/tuomiss1/conda_envs/ml-reproduci...</td>\n",
       "      <td>None</td>\n",
       "      <td>chill-donkey-189</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d9ac19da3eb438194fac049234036af</td>\n",
       "      <td>747633508105639431</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///tmp/mlflow/db/747633508105639431/5d9ac...</td>\n",
       "      <td>2025-11-10 21:49:05.178000+00:00</td>\n",
       "      <td>2025-11-10 21:49:12.203000+00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tuomiss1</td>\n",
       "      <td>/scratch/work/tuomiss1/conda_envs/ml-reproduci...</td>\n",
       "      <td>None</td>\n",
       "      <td>peaceful-fowl-174</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3b2bedf65917449e8da4c3f124f0304b</td>\n",
       "      <td>747633508105639431</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>file:///tmp/mlflow/db/747633508105639431/3b2be...</td>\n",
       "      <td>2025-11-10 21:36:56.192000+00:00</td>\n",
       "      <td>2025-11-10 21:38:02.178000+00:00</td>\n",
       "      <td>0.952250</td>\n",
       "      <td>0.167361</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0.01</td>\n",
       "      <td>checkpoints/epoch_4/checkpoint.pth</td>\n",
       "      <td>tuomiss1</td>\n",
       "      <td>/scratch/work/tuomiss1/conda_envs/ml-reproduci...</td>\n",
       "      <td>training</td>\n",
       "      <td>traveling-grouse-320</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id       experiment_id    status  \\\n",
       "0  813832b599c34bf38414eaa025b6845d  747633508105639431  FINISHED   \n",
       "1  a76fc81ba9f441c09c58c0e2d3b4a056  747633508105639431  FINISHED   \n",
       "2  cb6348373b004ecc98032a51a769b8a2  747633508105639431    FAILED   \n",
       "3  5d9ac19da3eb438194fac049234036af  747633508105639431  FINISHED   \n",
       "4  3b2bedf65917449e8da4c3f124f0304b  747633508105639431  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  file:///tmp/mlflow/db/747633508105639431/81383...   \n",
       "1  file:///tmp/mlflow/db/747633508105639431/a76fc...   \n",
       "2  file:///tmp/mlflow/db/747633508105639431/cb634...   \n",
       "3  file:///tmp/mlflow/db/747633508105639431/5d9ac...   \n",
       "4  file:///tmp/mlflow/db/747633508105639431/3b2be...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2025-11-10 22:03:42.797000+00:00 2025-11-10 22:04:49.251000+00:00   \n",
       "1 2025-11-10 21:58:47.133000+00:00 2025-11-10 21:59:50.084000+00:00   \n",
       "2 2025-11-10 21:58:07.339000+00:00 2025-11-10 21:58:07.346000+00:00   \n",
       "3 2025-11-10 21:49:05.178000+00:00 2025-11-10 21:49:12.203000+00:00   \n",
       "4 2025-11-10 21:36:56.192000+00:00 2025-11-10 21:38:02.178000+00:00   \n",
       "\n",
       "   metrics.training_accuracy  metrics.training_loss params.differentiable  \\\n",
       "0                   0.950533               0.168893                 False   \n",
       "1                   0.952867               0.164744                 False   \n",
       "2                        NaN                    NaN                  None   \n",
       "3                        NaN                    NaN                  None   \n",
       "4                   0.952250               0.167361                 False   \n",
       "\n",
       "  params.capturable  ... params.maximize params.fused params.weight_decay  \\\n",
       "0             False  ...           False         None                0.01   \n",
       "1             False  ...           False         None                0.01   \n",
       "2              None  ...            None         None                None   \n",
       "3              None  ...            None         None                None   \n",
       "4             False  ...           False         None                0.01   \n",
       "\n",
       "  tags.mlflow.latest_checkpoint_artifact tags.mlflow.user  \\\n",
       "0     checkpoints/epoch_4/checkpoint.pth         tuomiss1   \n",
       "1     checkpoints/epoch_4/checkpoint.pth         tuomiss1   \n",
       "2                                   None         tuomiss1   \n",
       "3                                   None         tuomiss1   \n",
       "4     checkpoints/epoch_4/checkpoint.pth         tuomiss1   \n",
       "\n",
       "                             tags.mlflow.source.name tags.Mode  \\\n",
       "0  /scratch/work/tuomiss1/conda_envs/ml-reproduci...  training   \n",
       "1  /scratch/work/tuomiss1/conda_envs/ml-reproduci...  training   \n",
       "2  /scratch/work/tuomiss1/conda_envs/ml-reproduci...      None   \n",
       "3  /scratch/work/tuomiss1/conda_envs/ml-reproduci...      None   \n",
       "4  /scratch/work/tuomiss1/conda_envs/ml-reproduci...  training   \n",
       "\n",
       "    tags.mlflow.runName tags.mlflow.source.type tags.mlflow.autologging  \n",
       "0       dashing-hen-904                   LOCAL                    None  \n",
       "1    fortunate-loon-636                   LOCAL                    None  \n",
       "2      chill-donkey-189                   LOCAL                    None  \n",
       "3     peaceful-fowl-174                   LOCAL                    None  \n",
       "4  traveling-grouse-320                   LOCAL                 pytorch  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.search_runs(experiment_names=[experiment_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db61e181-aa26-48dd-bea6-d9ad2bfdbdd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-reproducibility",
   "language": "python",
   "name": "ml-reproducibility"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
